{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow_decision_forests'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[333], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m \u001b[39mimport\u001b[39;00m Dense, Dropout, Flatten\n\u001b[0;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39moptimizers\u001b[39;00m \u001b[39mimport\u001b[39;00m Adam\n\u001b[1;32m---> 10\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow_decision_forests\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtfdf\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow_decision_forests'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow_decision_forests as tfdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Fourrier Austin Biking 30rpm.csv', 'Fourrier Austin Biking 30rpm.csv 0.png', 'Fourrier Austin Biking 30rpm.csv 1.png', 'Fourrier Austin Biking 30rpm.csv 2.png', 'Fourrier Austin Biking 30rpm.csv 3.png', 'Fourrier Austin Biking 30rpm.csv 4.png', 'Fourrier Austin Biking 30rpm.csv 5.png', 'Fourrier Austin Biking 30rpm.csv 6.png', 'Fourrier Austin Biking 30rpm.csv 7.png', 'Fourrier Austin Biking 30rpm.csv 8.png', 'Fourrier Austin Biking 60rpm.csv', 'Fourrier Austin Biking 60rpm.csv 0.png', 'Fourrier Austin Biking 60rpm.csv 1.png', 'Fourrier Austin Biking 60rpm.csv 2.png', 'Fourrier Austin Biking 60rpm.csv 3.png', 'Fourrier Austin Biking 60rpm.csv 4.png', 'Fourrier Austin Biking 60rpm.csv 5.png', 'Fourrier Austin Biking 60rpm.csv 6.png', 'Fourrier Austin Biking 60rpm.csv 7.png', 'Fourrier Austin Biking 60rpm.csv 8.png', 'Fourrier Austin Biking 90rpm.csv', 'Fourrier Austin Biking 90rpm.csv 0.png', 'Fourrier Austin Biking 90rpm.csv 1.png', 'Fourrier Austin Biking 90rpm.csv 2.png', 'Fourrier Austin Biking 90rpm.csv 3.png', 'Fourrier Austin Biking 90rpm.csv 4.png', 'Fourrier Austin Biking 90rpm.csv 5.png', 'Fourrier Austin Biking 90rpm.csv 6.png', 'Fourrier Austin Biking 90rpm.csv 7.png', 'Fourrier Austin Biking 90rpm.csv 8.png', 'Fourrier Austin Biking Variable rpm.csv', 'Fourrier Austin Biking Variable rpm.csv 0.png', 'Fourrier Austin Biking Variable rpm.csv 1.png', 'Fourrier Austin Biking Variable rpm.csv 2.png', 'Fourrier Austin Biking Variable rpm.csv 3.png', 'Fourrier Austin Biking Variable rpm.csv 4.png', 'Fourrier Austin Biking Variable rpm.csv 5.png', 'Fourrier Austin Biking Variable rpm.csv 6.png', 'Fourrier Austin Biking Variable rpm.csv 7.png', 'Fourrier Austin Biking Variable rpm.csv 8.png', 'Fourrier Austin Running 135spm, 8.5kph.csv', 'Fourrier Austin Running 135spm, 8.5kph.csv 0.png', 'Fourrier Austin Running 135spm, 8.5kph.csv 1.png', 'Fourrier Austin Running 135spm, 8.5kph.csv 2.png', 'Fourrier Austin Running 135spm, 8.5kph.csv 3.png', 'Fourrier Austin Running 135spm, 8.5kph.csv 4.png', 'Fourrier Austin Running 135spm, 8.5kph.csv 5.png', 'Fourrier Austin Running 135spm, 8.5kph.csv 6.png', 'Fourrier Austin Running 135spm, 8.5kph.csv 7.png', 'Fourrier Austin Running 135spm, 8.5kph.csv 8.png', 'Fourrier Austin Running 150spm, 10kph.csv', 'Fourrier Austin Running 150spm, 10kph.csv 0.png', 'Fourrier Austin Running 150spm, 10kph.csv 1.png', 'Fourrier Austin Running 150spm, 10kph.csv 2.png', 'Fourrier Austin Running 150spm, 10kph.csv 3.png', 'Fourrier Austin Running 150spm, 10kph.csv 4.png', 'Fourrier Austin Running 150spm, 10kph.csv 5.png', 'Fourrier Austin Running 150spm, 10kph.csv 6.png', 'Fourrier Austin Running 150spm, 10kph.csv 7.png', 'Fourrier Austin Running 150spm, 10kph.csv 8.png', 'Fourrier Austin Running 160spm, 12kph.csv', 'Fourrier Austin Running 160spm, 12kph.csv 0.png', 'Fourrier Austin Running 160spm, 12kph.csv 1.png', 'Fourrier Austin Running 160spm, 12kph.csv 2.png', 'Fourrier Austin Running 160spm, 12kph.csv 3.png', 'Fourrier Austin Running 160spm, 12kph.csv 4.png', 'Fourrier Austin Running 160spm, 12kph.csv 5.png', 'Fourrier Austin Running 160spm, 12kph.csv 6.png', 'Fourrier Austin Running 160spm, 12kph.csv 7.png', 'Fourrier Austin Running 160spm, 12kph.csv 8.png', 'Fourrier Austin Running 3 Speed with SPM labels.csv', 'Fourrier Austin Running 3 Speed with SPM labels.csv 0.png', 'Fourrier Austin Running 3 Speed with SPM labels.csv 1.png', 'Fourrier Austin Running 3 Speed with SPM labels.csv 2.png', 'Fourrier Austin Running 3 Speed with SPM labels.csv 3.png', 'Fourrier Austin Running 3 Speed with SPM labels.csv 4.png', 'Fourrier Austin Running 3 Speed with SPM labels.csv 5.png', 'Fourrier Austin Running 3 Speed with SPM labels.csv 6.png', 'Fourrier Austin Running 3 Speed with SPM labels.csv 7.png', 'Fourrier Austin Running 3 Speed with SPM labels.csv 8.png', 'Fourrier Austin Sitting.csv', 'Fourrier Austin Sitting.csv 0.png', 'Fourrier Austin Sitting.csv 1.png', 'Fourrier Austin Sitting.csv 2.png', 'Fourrier Austin Sitting.csv 3.png', 'Fourrier Austin Sitting.csv 4.png', 'Fourrier Austin Sitting.csv 5.png', 'Fourrier Austin Sitting.csv 6.png', 'Fourrier Austin Sitting.csv 7.png', 'Fourrier Austin Sitting.csv 8.png', 'Fourrier Austin Walk Run Cycle.csv', 'Fourrier Austin Walk Run Cycle.csv 0.png', 'Fourrier Austin Walk Run Cycle.csv 1.png', 'Fourrier Austin Walk Run Cycle.csv 2.png', 'Fourrier Austin Walk Run Cycle.csv 3.png', 'Fourrier Austin Walk Run Cycle.csv 4.png', 'Fourrier Austin Walk Run Cycle.csv 5.png', 'Fourrier Austin Walk Run Cycle.csv 6.png', 'Fourrier Austin Walk Run Cycle.csv 7.png', 'Fourrier Austin Walk Run Cycle.csv 8.png', 'Fourrier Austin Walking Inside 60spm.csv', 'Fourrier Austin Walking Inside 60spm.csv 0.png', 'Fourrier Austin Walking Inside 60spm.csv 1.png', 'Fourrier Austin Walking Inside 60spm.csv 2.png', 'Fourrier Austin Walking Inside 60spm.csv 3.png', 'Fourrier Austin Walking Inside 60spm.csv 4.png', 'Fourrier Austin Walking Inside 60spm.csv 5.png', 'Fourrier Austin Walking Inside 60spm.csv 6.png', 'Fourrier Austin Walking Inside 60spm.csv 7.png', 'Fourrier Austin Walking Inside 60spm.csv 8.png', 'Fourrier Austin Walking Inside 90spm.csv', 'Fourrier Austin Walking Inside 90spm.csv 0.png', 'Fourrier Austin Walking Inside 90spm.csv 1.png', 'Fourrier Austin Walking Inside 90spm.csv 2.png', 'Fourrier Austin Walking Inside 90spm.csv 3.png', 'Fourrier Austin Walking Inside 90spm.csv 4.png', 'Fourrier Austin Walking Inside 90spm.csv 5.png', 'Fourrier Austin Walking Inside 90spm.csv 6.png', 'Fourrier Austin Walking Inside 90spm.csv 7.png', 'Fourrier Austin Walking Inside 90spm.csv 8.png', 'Fourrier Austin Walking Outside 60spm.csv', 'Fourrier Austin Walking Outside 60spm.csv 0.png', 'Fourrier Austin Walking Outside 60spm.csv 1.png', 'Fourrier Austin Walking Outside 60spm.csv 2.png', 'Fourrier Austin Walking Outside 60spm.csv 3.png', 'Fourrier Austin Walking Outside 60spm.csv 4.png', 'Fourrier Austin Walking Outside 60spm.csv 5.png', 'Fourrier Austin Walking Outside 60spm.csv 6.png', 'Fourrier Austin Walking Outside 60spm.csv 7.png', 'Fourrier Austin Walking Outside 60spm.csv 8.png', 'Fourrier Austin Walking Outside 90spm.csv', 'Fourrier Austin Walking Outside 90spm.csv 0.png', 'Fourrier Austin Walking Outside 90spm.csv 1.png', 'Fourrier Austin Walking Outside 90spm.csv 2.png', 'Fourrier Austin Walking Outside 90spm.csv 3.png', 'Fourrier Austin Walking Outside 90spm.csv 4.png', 'Fourrier Austin Walking Outside 90spm.csv 5.png', 'Fourrier Austin Walking Outside 90spm.csv 6.png', 'Fourrier Austin Walking Outside 90spm.csv 7.png', 'Fourrier Austin Walking Outside 90spm.csv 8.png', 'Fourrier Austin Walking Treadmill, 110, 100, 85spm.csv', 'Fourrier Austin Walking Treadmill, 110, 100, 85spm.csv 0.png', 'Fourrier Austin Walking Treadmill, 110, 100, 85spm.csv 1.png', 'Fourrier Austin Walking Treadmill, 110, 100, 85spm.csv 2.png', 'Fourrier Austin Walking Treadmill, 110, 100, 85spm.csv 3.png', 'Fourrier Austin Walking Treadmill, 110, 100, 85spm.csv 4.png', 'Fourrier Austin Walking Treadmill, 110, 100, 85spm.csv 5.png', 'Fourrier Austin Walking Treadmill, 110, 100, 85spm.csv 6.png', 'Fourrier Austin Walking Treadmill, 110, 100, 85spm.csv 7.png', 'Fourrier Austin Walking Treadmill, 110, 100, 85spm.csv 8.png', 'Fourrier Austin Walking Variable spm.csv', 'Fourrier Austin Walking Variable spm.csv 0.png', 'Fourrier Austin Walking Variable spm.csv 1.png', 'Fourrier Austin Walking Variable spm.csv 2.png', 'Fourrier Austin Walking Variable spm.csv 3.png', 'Fourrier Austin Walking Variable spm.csv 4.png', 'Fourrier Austin Walking Variable spm.csv 5.png', 'Fourrier Austin Walking Variable spm.csv 6.png', 'Fourrier Austin Walking Variable spm.csv 7.png', 'Fourrier Austin Walking Variable spm.csv 8.png', 'Fourrier Georgios Biking 32rpm.csv', 'Fourrier Georgios Biking 32rpm.csv 0.png', 'Fourrier Georgios Biking 32rpm.csv 1.png', 'Fourrier Georgios Biking 32rpm.csv 2.png', 'Fourrier Georgios Biking 32rpm.csv 3.png', 'Fourrier Georgios Biking 32rpm.csv 4.png', 'Fourrier Georgios Biking 32rpm.csv 5.png', 'Fourrier Georgios Biking 32rpm.csv 6.png', 'Fourrier Georgios Biking 32rpm.csv 7.png', 'Fourrier Georgios Biking 32rpm.csv 8.png', 'Fourrier Georgios Biking 64rpm.csv', 'Fourrier Georgios Biking 64rpm.csv 0.png', 'Fourrier Georgios Biking 64rpm.csv 1.png', 'Fourrier Georgios Biking 64rpm.csv 2.png', 'Fourrier Georgios Biking 64rpm.csv 3.png', 'Fourrier Georgios Biking 64rpm.csv 4.png', 'Fourrier Georgios Biking 64rpm.csv 5.png', 'Fourrier Georgios Biking 64rpm.csv 6.png', 'Fourrier Georgios Biking 64rpm.csv 7.png', 'Fourrier Georgios Biking 64rpm.csv 8.png', 'Fourrier Georgios Tredmil 60-64-80spm.csv', 'Fourrier Georgios Tredmil 60-64-80spm.csv 0.png', 'Fourrier Georgios Tredmil 60-64-80spm.csv 1.png', 'Fourrier Georgios Tredmil 60-64-80spm.csv 2.png', 'Fourrier Georgios Tredmil 60-64-80spm.csv 3.png', 'Fourrier Georgios Tredmil 60-64-80spm.csv 4.png', 'Fourrier Georgios Tredmil 60-64-80spm.csv 5.png', 'Fourrier Georgios Tredmil 60-64-80spm.csv 6.png', 'Fourrier Georgios Tredmil 60-64-80spm.csv 7.png', 'Fourrier Georgios Tredmil 60-64-80spm.csv 8.png', 'Fourrier Georgios Walk Bike Run.csv', 'Fourrier Georgios Walk Bike Run.csv 0.png', 'Fourrier Georgios Walk Bike Run.csv 1.png', 'Fourrier Georgios Walk Bike Run.csv 2.png', 'Fourrier Georgios Walk Bike Run.csv 3.png', 'Fourrier Georgios Walk Bike Run.csv 4.png', 'Fourrier Georgios Walk Bike Run.csv 5.png', 'Fourrier Georgios Walk Bike Run.csv 6.png', 'Fourrier Georgios Walk Bike Run.csv 7.png', 'Fourrier Georgios Walk Bike Run.csv 8.png', 'Fourrier Georgios Walking Outside 30spm.csv', 'Fourrier Georgios Walking Outside 30spm.csv 0.png', 'Fourrier Georgios Walking Outside 30spm.csv 1.png', 'Fourrier Georgios Walking Outside 30spm.csv 2.png', 'Fourrier Georgios Walking Outside 30spm.csv 3.png', 'Fourrier Georgios Walking Outside 30spm.csv 4.png', 'Fourrier Georgios Walking Outside 30spm.csv 5.png', 'Fourrier Georgios Walking Outside 30spm.csv 6.png', 'Fourrier Georgios Walking Outside 30spm.csv 7.png', 'Fourrier Georgios Walking Outside 30spm.csv 8.png', 'Fourrier Georgios Walking Outside 60spm.csv', 'Fourrier Georgios Walking Outside 60spm.csv 0.png', 'Fourrier Georgios Walking Outside 60spm.csv 1.png', 'Fourrier Georgios Walking Outside 60spm.csv 2.png', 'Fourrier Georgios Walking Outside 60spm.csv 3.png', 'Fourrier Georgios Walking Outside 60spm.csv 4.png', 'Fourrier Georgios Walking Outside 60spm.csv 5.png', 'Fourrier Georgios Walking Outside 60spm.csv 6.png', 'Fourrier Georgios Walking Outside 60spm.csv 7.png', 'Fourrier Georgios Walking Outside 60spm.csv 8.png', 'Fourrier Georgios Walking Tredmil 60spm.csv', 'Fourrier Georgios Walking Tredmil 60spm.csv 0.png', 'Fourrier Georgios Walking Tredmil 60spm.csv 1.png', 'Fourrier Georgios Walking Tredmil 60spm.csv 2.png', 'Fourrier Georgios Walking Tredmil 60spm.csv 3.png', 'Fourrier Georgios Walking Tredmil 60spm.csv 4.png', 'Fourrier Georgios Walking Tredmil 60spm.csv 5.png', 'Fourrier Georgios Walking Tredmil 60spm.csv 6.png', 'Fourrier Georgios Walking Tredmil 60spm.csv 7.png', 'Fourrier Georgios Walking Tredmil 60spm.csv 8.png']\n",
      "['Fourrier Austin Biking 30rpm.csv', 'Fourrier Austin Biking 60rpm.csv', 'Fourrier Austin Biking 90rpm.csv', 'Fourrier Austin Biking Variable rpm.csv', 'Fourrier Austin Running 135spm, 8.5kph.csv', 'Fourrier Austin Running 150spm, 10kph.csv', 'Fourrier Austin Running 160spm, 12kph.csv', 'Fourrier Austin Running 3 Speed with SPM labels.csv', 'Fourrier Austin Sitting.csv', 'Fourrier Austin Walk Run Cycle.csv', 'Fourrier Austin Walking Inside 60spm.csv', 'Fourrier Austin Walking Inside 90spm.csv', 'Fourrier Austin Walking Outside 60spm.csv', 'Fourrier Austin Walking Outside 90spm.csv', 'Fourrier Austin Walking Treadmill, 110, 100, 85spm.csv', 'Fourrier Austin Walking Variable spm.csv', 'Fourrier Georgios Biking 32rpm.csv', 'Fourrier Georgios Biking 64rpm.csv', 'Fourrier Georgios Tredmil 60-64-80spm.csv', 'Fourrier Georgios Walk Bike Run.csv', 'Fourrier Georgios Walking Outside 30spm.csv', 'Fourrier Georgios Walking Outside 60spm.csv', 'Fourrier Georgios Walking Tredmil 60spm.csv']\n"
     ]
    }
   ],
   "source": [
    "files = os.listdir('./Fourrier/')\n",
    "print(files)\n",
    "files2 = []\n",
    "for i in range(int(len(files)/10)):\n",
    "    files2.append(files[i*10])\n",
    "print(files2)\n",
    "Viable_Cols = ['Acceleration x (m/s^2)_kalman', 'Acceleration y (m/s^2)_kalman', 'Acceleration z (m/s^2)_kalman', 'Gyroscope x (rad/s)_kalman',\n",
    "              'Gyroscope y (rad/s)_kalman', 'Gyroscope z (rad/s)_kalman', 'Linear Acceleration x (m/s^2)_kalman',\n",
    "              'Linear Acceleration y (m/s^2)_kalman', 'Linear Acceleration z (m/s^2)_kalman']\n",
    "Viable_Cols2 = []\n",
    "Viable_Cols3 = copy.deepcopy(Viable_Cols)\n",
    "for column in Viable_Cols:\n",
    "    newCol = str(column+'_max_freq')\n",
    "    Viable_Cols2.append(newCol)\n",
    "    Viable_Cols3.append(newCol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "279\n",
      "5786\n",
      "20.0\n"
     ]
    }
   ],
   "source": [
    "window = 200\n",
    "slide = 0.1\n",
    "train_test = 0.8\n",
    "def make_windows(window, slide, frame, train_test):\n",
    "    jump = window*slide\n",
    "    train_samples = []\n",
    "    sparse_train = []\n",
    "    test_samples = []\n",
    "    sparse_test = []\n",
    "    for i in range(int(len(frame['Acceleration x (m/s^2)_kalman'])/(window*slide))-int((1/slide))):\n",
    "        #print(i*20+200)\n",
    "        sample = frame.loc[(i*20):(i*20)+199, Viable_Cols]\n",
    "        sample2 = []\n",
    "        freqs = frame.loc[(i*20)+199, Viable_Cols2]\n",
    "        sample2.append(freqs.tolist())\n",
    "        mins = [np.min(sample[col]) for col in Viable_Cols]\n",
    "        maxes = [np.max(sample[col]) for col in Viable_Cols]\n",
    "        stdev = [np.std(sample[col], axis=0) for col in Viable_Cols]\n",
    "        sample2.append(mins)\n",
    "        sample2.append(maxes)\n",
    "        sample2.append(stdev)\n",
    "        if i*20 <= len(frame['Acceleration x (m/s^2)_kalman'])*train_test:\n",
    "            train_samples.append(sample)\n",
    "            sparse_train.append(sample2)\n",
    "        else:\n",
    "            test_samples.append(sample)\n",
    "            sparse_test.append(sample2)\n",
    "        \n",
    "        test_samples = test_samples[9:]\n",
    "        sparse_test = sparse_test[9:]\n",
    "    return train_samples, sparse_train, test_samples, sparse_test\n",
    "frame = pd.read_csv('./Fourrier/Fourrier Austin Biking 60rpm.csv')\n",
    "print(int(len(frame['Acceleration x (m/s^2)_kalman'])/(window*slide))-10)\n",
    "print(len(frame['Acceleration x (m/s^2)']))\n",
    "print(window*slide)\n",
    "#train_samples, sparse_train, test_samples, sparse_test = make_windows(window, slide, frame, train_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 200\n",
    "slide = 0.1\n",
    "train_test = 0.8\n",
    "def make_windows_PCA(window, slide, frame, train_test):\n",
    "    Viable_Cols = ['0', '1', '2', '3', '4', '5']\n",
    "    Viable_Cols2 = ['0_max_freq', '1_max_freq', '2_max_freq', '3_max_freq', '4_max_freq', '5_max_freq', ]\n",
    "    jump = window*slide\n",
    "    train_samples = []\n",
    "    sparse_train = []\n",
    "    test_samples = []\n",
    "    sparse_test = []\n",
    "    labels_train = []\n",
    "    labels_test = []\n",
    "    if 'SPM/RPM' in frame.columns:\n",
    "        label = 'SPM/RPM'\n",
    "    if 'RPM/SPM' in frame.columns:\n",
    "        label = 'RPM/SPM'\n",
    "    if 'RPM' in frame.columns:\n",
    "        label = 'RPM'\n",
    "    if 'SPM' in frame.columns:\n",
    "        label = 'SPM'\n",
    "    for i in range(int(len(frame['0'])/(window*slide))-int((1/slide))):\n",
    "        sample = frame.loc[(i*jump)+1:(i*jump)+(window), Viable_Cols]\n",
    "        sample2 = []\n",
    "        freqs = frame.loc[(i*jump)+200, Viable_Cols2]\n",
    "        sample2.append(freqs.tolist())\n",
    "        mins = [np.min(sample[col]) for col in Viable_Cols]\n",
    "        maxes = [np.max(sample[col]) for col in Viable_Cols]\n",
    "        stdev = [np.std(sample[col], axis=0) for col in Viable_Cols]\n",
    "        means = [np.mean(sample[col]) for col in Viable_Cols]\n",
    "        sample2.append(mins)\n",
    "        sample2.append(maxes)\n",
    "        sample2.append(stdev)\n",
    "        sample2.append(means)\n",
    "        yval = frame[label][(i*jump)+199]\n",
    "        if i*jump <= (len(frame['0'])*train_test):\n",
    "            train_samples.append(sample)\n",
    "            sparse_train.append(sample2)\n",
    "            labels_train.append(yval)\n",
    "        else:\n",
    "            test_samples.append(sample)\n",
    "            sparse_test.append(sample2)\n",
    "            labels_test.append(yval)\n",
    "    labels_test = labels_test[9:]\n",
    "    test_samples = test_samples[9:]\n",
    "    sparse_test = sparse_test[9:]\n",
    "    return train_samples, sparse_train, test_samples, sparse_test, labels_train, labels_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir('./PCA Fourier/')\n",
    "bike_train_samples, bike_sparse_train, bike_test_samples, bike_sparse_test, bike_labels_train, bike_labels_test = [],[],[],[],[],[]\n",
    "walk_train_samples, walk_sparse_train, walk_test_samples, walk_sparse_test, walk_labels_train, walk_labels_test = [],[],[],[],[],[]\n",
    "run_train_samples, run_sparse_train, run_test_samples, run_sparse_test, run_labels_train, run_labels_test = [],[],[],[],[],[]\n",
    "\n",
    "Biking_Files = [0,1,2,16,17]\n",
    "for i in Biking_Files:\n",
    "    print('A')\n",
    "    frame = pd.read_csv('./PCA Fourier/'+str(files[i]))\n",
    "    train_samples, sparse_train, test_samples, sparse_test, labels_train, labels_test = make_windows_PCA(window, slide, frame, train_test)\n",
    "    bike_train_samples.extend(train_samples)\n",
    "    bike_sparse_train.extend(sparse_train)\n",
    "    bike_test_samples.extend(test_samples)\n",
    "    bike_sparse_test.extend(sparse_test)\n",
    "    bike_labels_train.extend(labels_train)\n",
    "    bike_labels_test.extend(labels_test)\n",
    "Walking_Files = [10,11,12,13,14,18,20,21]\n",
    "for i in Walking_Files:\n",
    "    print('B')\n",
    "    frame = pd.read_csv('./PCA Fourier/'+str(files[i]))\n",
    "    train_samples, sparse_train, test_samples, sparse_test, labels_train, labels_test = make_windows_PCA(window, slide, frame, train_test)\n",
    "    walk_train_samples.extend(train_samples)\n",
    "    walk_sparse_train.extend(sparse_train)\n",
    "    walk_test_samples.extend(test_samples)\n",
    "    walk_sparse_test.extend(sparse_test)\n",
    "    walk_labels_train.extend(labels_train)\n",
    "    walk_labels_test.extend(labels_test)\n",
    "Running_Files = [4,5,6,7]\n",
    "for i in Running_Files:\n",
    "    print('C')\n",
    "    frame = pd.read_csv('./PCA Fourier/'+str(files[i]))\n",
    "    train_samples, sparse_train, test_samples, sparse_test, labels_train, labels_test = make_windows_PCA(window, slide, frame, train_test)\n",
    "    run_train_samples.extend(train_samples)\n",
    "    run_sparse_train.extend(sparse_train)\n",
    "    run_test_samples.extend(test_samples)\n",
    "    run_sparse_test.extend(sparse_test)\n",
    "    run_labels_train.extend(labels_train)\n",
    "    run_labels_test.extend(labels_test)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(run_train_samples))\n",
    "print(len(walk_train_samples))\n",
    "print(len(bike_train_samples))\n",
    "print(len(run_test_samples))\n",
    "print(len(walk_test_samples))\n",
    "print(len(bike_test_samples))\n",
    "print(len(bike_labels_test))\n",
    "print(run_train_samples[1])\n",
    "print(run_sparse_train[1])\n",
    "\n",
    "def reshaper(frame):\n",
    "    data_2d = frame.reshape(-1, frame.shape[-1])\n",
    "    scaler = StandardScaler()\n",
    "    whitened_data_2d = scaler.fit_transform(data_2d)\n",
    "    whitened_frame = whitened_data_2d.reshape(frame.shape)\n",
    "    return whitened_frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_run_sparse_train = np.array(run_sparse_train)\n",
    "tf_run_labels_train = np.array(run_labels_train)\n",
    "tf_run_sparse_test = np.array(run_sparse_test)\n",
    "tf_run_labels_test = np.array(run_labels_test)\n",
    "\n",
    "whitened_run_sparse_train = reshaper(tf_run_sparse_train)\n",
    "whitened_run_sparse_test = reshaper(tf_run_sparse_test)\n",
    "\n",
    "model_run = Sequential([\n",
    "    Flatten(input_shape=(5,6)),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.1),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.1),\n",
    "    Dense(1, activation='relu')])\n",
    "model_run.compile(optimizer=Adam(learning_rate=0.02), loss='mean_absolute_error', metrics=['mean_absolute_error'])\n",
    "model_run.fit(whitened_run_sparse_train, tf_run_labels_train, epochs=10)\n",
    "model_run.evaluate(whitened_run_sparse_test, tf_run_labels_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_walk_sparse_train = np.array(walk_sparse_train)\n",
    "tf_walk_labels_train = np.array(walk_labels_train)\n",
    "tf_walk_sparse_test = np.array(walk_sparse_test)\n",
    "tf_walk_labels_test = np.array(walk_labels_test)\n",
    "\n",
    "whitened_walk_sparse_train = reshaper(tf_walk_sparse_train)\n",
    "whitened_walk_sparse_test = reshaper(tf_walk_sparse_test)\n",
    "\n",
    "model_walk = Sequential([\n",
    "    Flatten(input_shape=(5,6)),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(1, activation='relu')])\n",
    "model_walk.compile(optimizer=Adam(learning_rate=0.1), loss='mean_absolute_error', metrics=['mean_absolute_error'])\n",
    "model_walk.fit(whitened_walk_sparse_train, tf_walk_labels_train, epochs=10)\n",
    "model_walk.evaluate(whitened_walk_sparse_test, tf_walk_labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 30.6762 - mean_absolute_error: 30.6762\n",
      "Epoch 2/10\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 16.6507 - mean_absolute_error: 16.6507\n",
      "Epoch 3/10\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 13.8011 - mean_absolute_error: 13.8011\n",
      "Epoch 4/10\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 11.0550 - mean_absolute_error: 11.0550\n",
      "Epoch 5/10\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 9.9959 - mean_absolute_error: 9.9959\n",
      "Epoch 6/10\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 11.7806 - mean_absolute_error: 11.7806\n",
      "Epoch 7/10\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 10.4581 - mean_absolute_error: 10.4581\n",
      "Epoch 8/10\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 11.3227 - mean_absolute_error: 11.3227\n",
      "Epoch 9/10\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 10.8202 - mean_absolute_error: 10.8202\n",
      "Epoch 10/10\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 10.7185 - mean_absolute_error: 10.7185\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 10.0213 - mean_absolute_error: 10.0213\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[10.021334648132324, 10.021334648132324]"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_bike_sparse_train = np.array(bike_sparse_train)\n",
    "tf_bike_labels_train = np.array(bike_labels_train)\n",
    "tf_bike_sparse_test = np.array(bike_sparse_test)\n",
    "tf_bike_labels_test = np.array(bike_labels_test)\n",
    "\n",
    "whitened_bike_sparse_train = reshaper(tf_bike_sparse_train)\n",
    "whitened_bike_sparse_test = reshaper(tf_bike_sparse_test)\n",
    "\n",
    "model_bike = Sequential([\n",
    "    Flatten(input_shape=(5,6)),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(1, activation='relu')])\n",
    "model_bike.compile(optimizer=tf.optimizers.Adam(learning_rate=0.1), loss='mean_absolute_error', metrics=['mean_absolute_error'])\n",
    "model_bike.fit(whitened_bike_sparse_train, tf_bike_labels_train, epochs=10)\n",
    "model_bike.evaluate(whitened_bike_sparse_test, tf_bike_labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_windows_full_dataset(window, slide, frame, train_test):\n",
    "    Viable_Cols = ['0', '1', '2', '3', '4', '5']\n",
    "    Viable_Cols2 = ['0_max_freq', '1_max_freq', '2_max_freq', '3_max_freq', '4_max_freq', '5_max_freq', ]\n",
    "    jump = window*slide\n",
    "    train_samples = []\n",
    "    sparse_train = []\n",
    "    test_samples = []\n",
    "    sparse_test = []\n",
    "    labels_train = []\n",
    "    labels_test = []\n",
    "    for i in range(int(len(frame['0'])/(window*slide))-int((1/slide))):\n",
    "        print(i*jump)\n",
    "        sample = frame.loc[(i*jump):(i*jump)+(window-1), Viable_Cols]\n",
    "        sample2 = []\n",
    "        freqs = frame.loc[(i*jump)+199, Viable_Cols2]\n",
    "        sample2.append(freqs.tolist())\n",
    "        mins = [np.min(sample[col]) for col in Viable_Cols]\n",
    "        maxes = [np.max(sample[col]) for col in Viable_Cols]\n",
    "        stdev = [np.std(sample[col], axis=0) for col in Viable_Cols]\n",
    "        means = [np.mean(sample[col]) for col in Viable_Cols]\n",
    "        sample2.append(mins)\n",
    "        sample2.append(maxes)\n",
    "        sample2.append(stdev)\n",
    "        sample2.append(means)\n",
    "        if frame['Still'][(i*jump)+199] == 1:\n",
    "            yval = 0\n",
    "        if frame['Walk'][(i*jump)+199] == 1:\n",
    "            yval = 1\n",
    "        if frame['Run'][(i*jump)+199] == 1:\n",
    "            yval = 2\n",
    "        if frame['Cycle'][(i*jump)+199] == 1:\n",
    "            yval = 3\n",
    "        \n",
    "        if i*jump <= (len(frame['0'])*train_test):\n",
    "            train_samples.append(sample)\n",
    "            sparse_train.append(sample2)\n",
    "            labels_train.append(yval)\n",
    "        else:\n",
    "            test_samples.append(sample)\n",
    "            sparse_test.append(sample2)\n",
    "            labels_test.append(yval)\n",
    "    labels_test = labels_test[9:]\n",
    "    test_samples = test_samples[9:]\n",
    "    sparse_test = sparse_test[9:]\n",
    "    return train_samples, sparse_train, test_samples, sparse_test, labels_train, labels_test\n",
    "\n",
    "def sampler(train_samples, sparse_train, labels_train, num):\n",
    "    length = len(train_samples)\n",
    "    ids = random.sample(range(length), num)\n",
    "    dataSamples = []\n",
    "    sparseSamples = []\n",
    "    labelSamples = []\n",
    "    for i in ids:\n",
    "        dataSamples.append(train_samples[i])\n",
    "        sparseSamples.append(sparse_train[i])\n",
    "        labelSamples.append(labels_train[i])\n",
    "    return dataSamples, sparseSamples, labelSamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = pd.read_csv('Complete_dataset_PCA_Fourier.csv')\n",
    "train_samples, sparse_train, test_samples, sparse_test, labels_train, labels_test = make_windows_full_dataset(window, slide, frame, train_test)\n",
    "num = 20\n",
    "dataSamples, sparseSamples, labelSamples = sampler(train_samples, sparse_train, labels_train, num)\n",
    "tf_sparse_train = np.array(sparse_train)\n",
    "tf_labels_train = np.array(labels_train)\n",
    "tf_sparse_test = np.array(sparse_test)\n",
    "tf_labels_test = np.array(labels_test)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5792, 5, 6)\n",
      "[[ 0.28095727 -0.16922378  0.98886819  1.03413009  0.50321319  0.04874273]\n",
      " [-0.53132363 -1.35084082 -1.02818922 -0.99882539 -0.54503232 -1.45949958]\n",
      " [ 0.38855584 -0.29629351  0.82851656  0.3124203   0.68795766  0.21776652]\n",
      " [-0.10627362 -0.11335044 -0.04700736 -0.05525641  0.00859163  0.03064378]\n",
      " [-0.1428993  -0.68177014 -0.30601845 -0.20604174 -0.048618   -0.77097134]]\n",
      "Epoch 1/5\n",
      "181/181 [==============================] - 1s 1ms/step - loss: 0.4162 - accuracy: 0.8499\n",
      "Epoch 2/5\n",
      "181/181 [==============================] - 0s 1ms/step - loss: 0.1844 - accuracy: 0.9249\n",
      "Epoch 3/5\n",
      "181/181 [==============================] - 0s 1ms/step - loss: 0.1528 - accuracy: 0.9289\n",
      "Epoch 4/5\n",
      "181/181 [==============================] - 0s 1ms/step - loss: 0.1384 - accuracy: 0.9346\n",
      "Epoch 5/5\n",
      "181/181 [==============================] - 0s 1ms/step - loss: 0.1283 - accuracy: 0.9389\n",
      "45/45 [==============================] - 0s 680us/step - loss: 0.5863 - accuracy: 0.8219\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5863395929336548, 0.8218793869018555]"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf_sparse_train.shape)\n",
    "whitened_tf_sparse_train = reshaper(tf_sparse_train[1:])\n",
    "print(whitened_tf_sparse_train[0])\n",
    "\n",
    "model_classify = tf.keras.models.Sequential([\n",
    "    Flatten(input_shape=(5,6)),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(4, activation='softmax')])\n",
    "model_classify.compile(optimizer=tf.optimizers.Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model_classify.fit(whitened_tf_sparse_train, tf_labels_train[1:], epochs=5)\n",
    "whitened_tf_sparse_test = reshaper(tf_sparse_test[1:])\n",
    "model_classify.evaluate(whitened_tf_sparse_test, tf_labels_test[1:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "181/181 [==============================] - 0s 578us/step\n",
      "87/87 [==============================] - 0s 504us/step\n",
      "30/30 [==============================] - 0s 570us/step\n",
      "31/31 [==============================] - 0s 574us/step\n",
      "You walked for 45.9 minutes at a pace of 72 steps per minute on average\n",
      "You ran for 15.85 minutes at a pace of 148 steps per minute on average\n",
      "You biked for 16.28 minutes at a pace of 48 revolutions per minute on average\n"
     ]
    }
   ],
   "source": [
    "predictions = model_classify.predict(whitened_tf_sparse_train)\n",
    "still = []\n",
    "walk = []\n",
    "run = []\n",
    "bike = []\n",
    "for i, item in enumerate(predictions):\n",
    "    if np.argmax(item) == 0:\n",
    "        still.append(whitened_tf_sparse_train[i])\n",
    "    if np.argmax(item) == 1:\n",
    "        walk.append(whitened_tf_sparse_train[i])\n",
    "    if np.argmax(item) == 2:\n",
    "        run.append(whitened_tf_sparse_train[i])\n",
    "    if np.argmax(item) == 3:\n",
    "        bike.append(whitened_tf_sparse_train[i])\n",
    "walk_cad = model_walk.predict(np.array(walk))\n",
    "run_cad = model_run.predict(np.array(run))\n",
    "bike_cad = model_bike.predict(np.array(bike))\n",
    "walk_time = len(walk)/(60)\n",
    "walk_avg = np.mean(walk_cad)\n",
    "run_time = len(run)/(60)\n",
    "run_avg = np.mean(run_cad)\n",
    "bike_time = len(bike)/(60)\n",
    "bike_avg = np.mean(bike_cad)\n",
    "print(\"You walked for \"+str(round(walk_time,2))+\" minutes at a pace of \"+str(int(walk_avg))+\" steps per minute on average\")\n",
    "print(\"You ran for \"+str(round(run_time,2))+\" minutes at a pace of \"+str(int(run_avg))+\" steps per minute on average\")\n",
    "print(\"You biked for \"+str(round(bike_time,2))+\" minutes at a pace of \"+str(int(bike_avg))+\" revolutions per minute on average\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9144460028050491\n",
      "[[  1   0   0   0]\n",
      " [  0 531   5   0]\n",
      " [  2  61 232   0]\n",
      " [ 45   9   0 540]]\n",
      "[[1072    0    0    0]\n",
      " [   0 2958    0    0]\n",
      " [   0    0  943    0]\n",
      " [   0    0    0  818]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "randomForest = RandomForestClassifier()\n",
    "whitened_tf_sparse_train_flat = whitened_tf_sparse_train.reshape(whitened_tf_sparse_train.shape[0], -1)\n",
    "whitened_tf_sparse_test_flat = whitened_tf_sparse_test.reshape(whitened_tf_sparse_test.shape[0], -1)\n",
    "randomForest.fit(whitened_tf_sparse_train_flat, tf_labels_train[1:])\n",
    "train_predictions = randomForest.predict(whitened_tf_sparse_train_flat)\n",
    "predictions = randomForest.predict(whitened_tf_sparse_test_flat)\n",
    "accuracy = accuracy_score(tf_labels_test[1:], predictions)\n",
    "print(f'Test accuracy: {accuracy}')\n",
    "confusion = confusion_matrix(tf_labels_test[1:], predictions)\n",
    "print(confusion)\n",
    "confusion_train = confusion_matrix(tf_labels_train[1:], train_predictions)\n",
    "print(confusion_train)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML4QSenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
